{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytz\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# Configuration - Update these paths to match your data location\n",
    "chatgpt_folder = os.getenv(\"CHATGPT_FOLDER\")\n",
    "claude_folder = os.getenv(\"CLAUDE_FOLDER\")\n",
    "local_tz = 'Asia/Kolkata'  # India timezone\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"visualizations\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load ChatGPT data\n",
    "try:\n",
    "    with open(f'{chatgpt_folder}/conversations.json', 'r') as f:\n",
    "        oai_convs = json.load(f)\n",
    "    print(f\"Loaded {len(oai_convs)} ChatGPT conversations\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading ChatGPT data: {e}\")\n",
    "    oai_convs = []\n",
    "\n",
    "# Load Claude data\n",
    "try:\n",
    "    with open(f'{claude_folder}/conversations.json', 'r') as f:\n",
    "        claude_convs = json.load(f)\n",
    "    print(f\"Loaded {len(claude_convs)} Claude conversations\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Claude data: {e}\")\n",
    "    claude_convs = []\n",
    "\n",
    "# Process ChatGPT timestamps\n",
    "oai_convo_times = []\n",
    "for conv in oai_convs:\n",
    "    # Given Unix timestamp\n",
    "    unix_timestamp = conv['create_time']\n",
    "    \n",
    "    # Convert to UTC datetime\n",
    "    utc_datetime = datetime.fromtimestamp(unix_timestamp, tz=timezone.utc)\n",
    "    \n",
    "    # Convert UTC datetime to local timezone\n",
    "    local_datetime = utc_datetime.astimezone(pytz.timezone(local_tz))\n",
    "    oai_convo_times.append(local_datetime)\n",
    "\n",
    "# Process Claude timestamps\n",
    "def convert_claude_timestamps(convs, local_tz):\n",
    "    convo_times = []\n",
    "    for conv in convs:\n",
    "        # Parse ISO format string to datetime\n",
    "        utc_datetime = datetime.strptime(conv['created_at'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "        # Add UTC timezone info\n",
    "        utc_datetime = utc_datetime.replace(tzinfo=timezone.utc)\n",
    "        \n",
    "        # Convert UTC to local timezone\n",
    "        local_datetime = utc_datetime.astimezone(pytz.timezone(local_tz))\n",
    "        convo_times.append(local_datetime)\n",
    "    \n",
    "    return convo_times\n",
    "\n",
    "claude_convo_times = convert_claude_timestamps(claude_convs, local_tz)\n",
    "\n",
    "# Get all available years from the data\n",
    "all_years = set()\n",
    "for dt in oai_convo_times:\n",
    "    all_years.add(dt.year)\n",
    "for dt in claude_convo_times:\n",
    "    all_years.add(dt.year)\n",
    "\n",
    "all_years = sorted(list(all_years))\n",
    "print(f\"Found conversations from these years: {all_years}\")\n",
    "\n",
    "# Create DataFrames for easier analysis\n",
    "chatgpt_df = pd.DataFrame({\n",
    "    'timestamp': oai_convo_times,\n",
    "    'assistant': 'ChatGPT'\n",
    "})\n",
    "\n",
    "claude_df = pd.DataFrame({\n",
    "    'timestamp': claude_convo_times,\n",
    "    'assistant': 'Claude'\n",
    "})\n",
    "\n",
    "# Combine both datasets\n",
    "combined_df = pd.concat([chatgpt_df, claude_df]).reset_index(drop=True)\n",
    "\n",
    "# Add additional time components for analysis\n",
    "combined_df['date'] = combined_df['timestamp'].dt.date\n",
    "combined_df['year'] = combined_df['timestamp'].dt.year\n",
    "combined_df['month'] = combined_df['timestamp'].dt.month\n",
    "combined_df['day'] = combined_df['timestamp'].dt.day\n",
    "combined_df['hour'] = combined_df['timestamp'].dt.hour\n",
    "combined_df['weekday'] = combined_df['timestamp'].dt.day_name()\n",
    "\n",
    "# Show summary statistics\n",
    "print(f\"Total conversations: {len(combined_df)}\")\n",
    "print(f\"ChatGPT conversations: {len(chatgpt_df)}\")\n",
    "print(f\"Claude conversations: {len(claude_df)}\")\n",
    "print(f\"Date range: {combined_df['date'].min()} to {combined_df['date'].max()}\")\n",
    "\n",
    "# Conversations per assistant per year\n",
    "yearly_summary = combined_df.groupby(['year', 'assistant']).size().unstack(fill_value=0)\n",
    "display(yearly_summary)\n",
    "\n",
    "# Define a function to create a heatmap for a single assistant\n",
    "def create_single_heatmap(convo_times, year, name, color_map, output_file=None):\n",
    "    # Convert convo_times to dates and filter for the given year\n",
    "    just_dates = [convo.date() for convo in convo_times if convo.year == year]\n",
    "    \n",
    "    date_counts = Counter(just_dates)\n",
    "    total_convos = sum(date_counts.values())\n",
    "    \n",
    "    if total_convos == 0:\n",
    "        print(f\"No {name} conversations found for year {year}, skipping visualization\")\n",
    "        return False\n",
    "    \n",
    "    # Create a full year date range for the calendar\n",
    "    start_date = datetime(year, 1, 1).date()\n",
    "    end_date = datetime(year, 12, 31).date()\n",
    "    \n",
    "    total_days = (end_date - start_date).days + 1\n",
    "    date_range = [start_date + timedelta(days=i) for i in range(total_days)]\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    data = []\n",
    "    for date in date_range:\n",
    "        week = ((date - start_date).days + start_date.weekday()) // 7\n",
    "        day_of_week = date.weekday()\n",
    "        count = date_counts.get(date, 0)\n",
    "        data.append((week, day_of_week, count))\n",
    "    \n",
    "    weeks_in_year = (end_date - start_date).days // 7 + 1\n",
    "    \n",
    "    # Find the most active day\n",
    "    max_count_date = max(date_counts.items(), key=lambda x: x[1]) if date_counts else (None, 0)\n",
    "    max_count = max_count_date[1] if max_count_date[0] is not None else 0\n",
    "    \n",
    "    # Calculate p90 for color scaling\n",
    "    p90_count = np.percentile(list(date_counts.values()), 90) if date_counts else 1\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    for week, day_of_week, count in data:\n",
    "        color = color_map((count + 1) / p90_count) if count > 0 else 'lightgray'\n",
    "        rect = patches.Rectangle((week, day_of_week), 1, 1, linewidth=0.5, edgecolor='black', facecolor=color)\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    # Replace week numbers with month names below the heatmap\n",
    "    month_starts = [start_date + timedelta(days=i) for i in range(total_days)\n",
    "                  if (start_date + timedelta(days=i)).day == 1]\n",
    "    for month_start in month_starts:\n",
    "        week = (month_start - start_date).days // 7\n",
    "        plt.text(week + 0.5, 7.75, month_start.strftime('%b'), ha='center', va='center', fontsize=10, rotation=0)\n",
    "    \n",
    "    # Adjustments for readability\n",
    "    ax.set_xlim(-0.5, weeks_in_year + 0.5)\n",
    "    ax.set_ylim(-0.5, 8.5)\n",
    "    plt.title(\n",
    "        f'{year} {name} Conversation Heatmap (total={total_convos})\\n'\n",
    "        f'Most active day: {max_count_date[0]} with {max_count} convos.',\n",
    "        fontsize=16\n",
    "    )\n",
    "    plt.xticks([])\n",
    "    plt.yticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved visualization to {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return True\n",
    "\n",
    "# Define the comparison heatmap function\n",
    "def create_comparison_heatmap(claude_times, openai_times, year, output_file=None):\n",
    "    # Convert times to dates and filter for the given year\n",
    "    claude_dates = [convo.date() for convo in claude_times if convo.year == year]\n",
    "    openai_dates = [convo.date() for convo in openai_times if convo.year == year]\n",
    "    \n",
    "    claude_counts = Counter(claude_dates)\n",
    "    openai_counts = Counter(openai_dates)\n",
    "    \n",
    "    # Calculate totals\n",
    "    claude_total = sum(claude_counts.values())\n",
    "    openai_total = sum(openai_counts.values())\n",
    "    combined_total = claude_total + openai_total\n",
    "    \n",
    "    if combined_total == 0:\n",
    "        print(f\"No conversations found for year {year}, skipping comparison visualization\")\n",
    "        return False\n",
    "    \n",
    "    # Create a full year date range\n",
    "    start_date = datetime(year, 1, 1).date()\n",
    "    end_date = datetime(year, 12, 31).date()\n",
    "    total_days = (end_date - start_date).days + 1\n",
    "    date_range = [start_date + timedelta(days=i) for i in range(total_days)]\n",
    "    \n",
    "    # Prepare data for plotting - Reverse the day_of_week calculation\n",
    "    data = []\n",
    "    for date in date_range:\n",
    "        week = ((date - start_date).days + start_date.weekday()) // 7\n",
    "        day_of_week = 6 - date.weekday()  # This reverses the order\n",
    "        claude_count = claude_counts.get(date, 0)\n",
    "        openai_count = openai_counts.get(date, 0)\n",
    "        dominant_llm = 'claude' if claude_count > openai_count else 'openai' if openai_count > claude_count else 'tie'\n",
    "        count = max(claude_count, openai_count)\n",
    "        data.append((week, day_of_week, count, dominant_llm))\n",
    "    \n",
    "    weeks_in_year = (end_date - start_date).days // 7 + 2\n",
    "    \n",
    "    # Calculate overall p90 for color scaling\n",
    "    all_counts = list(claude_counts.values()) + list(openai_counts.values())\n",
    "    p90_count = np.percentile(all_counts, 90) if all_counts else 1\n",
    "    \n",
    "    # Plot setup\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Plot rectangles\n",
    "    for week, day_of_week, count, dominant_llm in data:\n",
    "        if count > 0:\n",
    "            # Start at 0.1 (10%) intensity and scale up to 1\n",
    "            intensity = min(0.1 + (count / p90_count * 0.9), 1)\n",
    "            color = plt.cm.Oranges(intensity) if dominant_llm == 'claude' else \\\n",
    "                   plt.cm.Greens(intensity) if dominant_llm == 'openai' else \\\n",
    "                   'lightgray'\n",
    "        else:\n",
    "            color = '#F5F5F5'  # Light gray for empty cells\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (week, day_of_week), 1, 1,\n",
    "            linewidth=1,\n",
    "            edgecolor='black',\n",
    "            facecolor=color\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    # Add month labels\n",
    "    month_starts = [start_date + timedelta(days=i) for i in range(total_days)\n",
    "                   if (start_date + timedelta(days=i)).day == 1]\n",
    "    for month_start in month_starts:\n",
    "        week = (month_start - start_date).days // 7\n",
    "        plt.text(week + 0.5, -0.5, month_start.strftime('%b'),\n",
    "                ha='center', va='top', fontsize=10)\n",
    "    \n",
    "    # Find most active days\n",
    "    claude_max_date = max(claude_counts.items(), key=lambda x: x[1]) if claude_counts else (None, 0)\n",
    "    openai_max_date = max(openai_counts.items(), key=lambda x: x[1]) if openai_counts else (None, 0)\n",
    "    \n",
    "    # Title and formatting\n",
    "    plt.title(\n",
    "        f'{year} AI Conversation Comparison (Total: {combined_total:,} conversations)\\n'\n",
    "        f'Claude total: {claude_total:,}, max: {claude_max_date[1]} on {claude_max_date[0]}\\n'\n",
    "        f'OpenAI total: {openai_total:,}, max: {openai_max_date[1]} on {openai_max_date[0]}',\n",
    "        fontsize=12, pad=15\n",
    "    )\n",
    "    \n",
    "    # Adjust axis limits and labels\n",
    "    plt.xlim(-0.5, weeks_in_year + 0.5)\n",
    "    plt.ylim(-1, 7)\n",
    "    plt.xticks([])\n",
    "    \n",
    "    # Set y-ticks at the center of each box (offset by 0.5)\n",
    "    plt.yticks([i + 0.5 for i in range(7)], ['Sun', 'Sat', 'Fri', 'Thu', 'Wed', 'Tue', 'Mon'])\n",
    "    \n",
    "    # Adjust y-axis label positioning\n",
    "    ax.yaxis.set_tick_params(pad=10)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [\n",
    "        patches.Patch(facecolor=plt.cm.Oranges(0.7), label='Claude Dominant'),\n",
    "        patches.Patch(facecolor=plt.cm.Greens(0.7), label='OpenAI Dominant'),\n",
    "        patches.Patch(facecolor='lightgray', label='Tie')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1.02, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved visualization to {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return True\n",
    "\n",
    "# Usage patterns by hour of day\n",
    "plt.figure(figsize=(12, 6))\n",
    "hourly_usage = combined_df.groupby(['hour', 'assistant']).size().unstack(fill_value=0)\n",
    "hourly_usage.plot(kind='bar', stacked=True)\n",
    "plt.title('AI Usage by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Conversations')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Usage by day of week\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Set order for weekdays\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_usage = combined_df.groupby(['weekday', 'assistant']).size().unstack(fill_value=0)\n",
    "weekday_usage = weekday_usage.reindex(weekday_order)\n",
    "weekday_usage.plot(kind='bar', stacked=True)\n",
    "plt.title('AI Usage by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Conversations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Monthly trends over time\n",
    "combined_df['yearmonth'] = combined_df['timestamp'].dt.strftime('%Y-%m')\n",
    "monthly_usage = combined_df.groupby(['yearmonth', 'assistant']).size().unstack(fill_value=0)\n",
    "plt.figure(figsize=(15, 6))\n",
    "monthly_usage.plot(kind='line', marker='o')\n",
    "plt.title('Monthly AI Usage Trends')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Number of Conversations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Loop through all available years to generate heatmaps\n",
    "for year in all_years:\n",
    "    print(f\"\\nProcessing year {year}...\")\n",
    "    \n",
    "    # Create Claude heatmap for the year\n",
    "    create_single_heatmap(claude_convo_times, year, \"Claude\", plt.cm.Oranges, \n",
    "                     output_file=f\"{output_dir}/claude_heatmap_{year}.png\")\n",
    "    \n",
    "    # Create ChatGPT heatmap for the year\n",
    "    create_single_heatmap(oai_convo_times, year, \"ChatGPT\", plt.cm.Greens, \n",
    "                     output_file=f\"{output_dir}/chatgpt_heatmap_{year}.png\")\n",
    "    \n",
    "    # Create comparison heatmap for the year\n",
    "    create_comparison_heatmap(claude_convo_times, oai_convo_times, year, \n",
    "                          output_file=f\"{output_dir}/comparison_heatmap_{year}.png\")\n",
    "\n",
    "print(\"\\nVisualization process complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
